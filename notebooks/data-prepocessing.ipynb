{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Streaming_History_Audio_2020-2021_0.json'} : 15408\n",
      "{'Streaming_History_Audio_2020-2025.json'} : 46119\n",
      "{'Streaming_History_Audio_2021-2023_1.json'} : 15520\n",
      "{'Streaming_History_Audio_2023-2025_2.json'} : 15191\n",
      "{'Streaming_History_Video_2022-2024.json'} : 51\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "for filename in os.listdir('.'):\n",
    "    if filename.endswith('.json'):\n",
    "        with open(filename,'r') as f:\n",
    "            global_count = 0\n",
    "            data = json.load(f)\n",
    "            global_count += len(data)\n",
    "            \n",
    "        print({filename},':',global_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------\n",
      "{'Streaming_History_Audio_2020-2025.json'} already existed...So we are deleting it..\n",
      "-------------------------------------------------------------------\n",
      "Added 15408 items from Streaming_History_Audio_2020-2021_0.json\n",
      "Added 15520 items from Streaming_History_Audio_2021-2023_1.json\n",
      "Added 15191 items from Streaming_History_Audio_2023-2025_2.json\n",
      "Combined data written to 'Streaming_History_Audio_2020-2025.json' with 46119 items.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Initialize a list to hold combined data\n",
    "combined_data = []\n",
    "\n",
    "# Define the output filename\n",
    "output_filename = 'Streaming_History_Audio_2020-2025.json'\n",
    "\n",
    "# Check if the output file already exists and delete it if it does\n",
    "if os.path.exists(output_filename):\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    print({output_filename} ,\"already existed...So we are deleting it..\")\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    os.remove(output_filename)\n",
    "\n",
    "# Iterate through all JSON files in the current directory\n",
    "for filename in os.listdir('.'):\n",
    "    if filename.endswith('.json') and filename != 'Streaming_History_Video_2022-2024.json':\n",
    "        try:\n",
    "            with open(filename,'r') as f:\n",
    "                data = json.load(f)\n",
    "                combined_data.extend(data)\n",
    "                print(f\"Added {len(data)} items from {filename}\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Skipping invalid JSON file: {filename}\")\n",
    "                  \n",
    "\n",
    " # Write the combined data to a new JSON file   \n",
    "with open(output_filename,'w') as f:\n",
    "    json.dump(combined_data,f,indent=4)\n",
    "\n",
    "print(f\"Combined data written to 'Streaming_History_Audio_2020-2025.json' with {len(combined_data)} items.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in c:\\users\\mkalw\\anaconda3\\envs\\upgraded_py\\lib\\site-packages (0.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA EXPLORATION STAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46119 entries, 0 to 46118\n",
      "Data columns (total 23 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   ts                                 46119 non-null  object \n",
      " 1   platform                           46119 non-null  object \n",
      " 2   ms_played                          46119 non-null  int64  \n",
      " 3   conn_country                       46119 non-null  object \n",
      " 4   ip_addr                            46119 non-null  object \n",
      " 5   master_metadata_track_name         45838 non-null  object \n",
      " 6   master_metadata_album_artist_name  45838 non-null  object \n",
      " 7   master_metadata_album_album_name   45838 non-null  object \n",
      " 8   spotify_track_uri                  45838 non-null  object \n",
      " 9   episode_name                       281 non-null    object \n",
      " 10  episode_show_name                  281 non-null    object \n",
      " 11  spotify_episode_uri                281 non-null    object \n",
      " 12  audiobook_title                    0 non-null      float64\n",
      " 13  audiobook_uri                      0 non-null      float64\n",
      " 14  audiobook_chapter_uri              0 non-null      float64\n",
      " 15  audiobook_chapter_title            0 non-null      float64\n",
      " 16  reason_start                       46119 non-null  object \n",
      " 17  reason_end                         46119 non-null  object \n",
      " 18  shuffle                            46119 non-null  bool   \n",
      " 19  skipped                            46119 non-null  bool   \n",
      " 20  offline                            46119 non-null  bool   \n",
      " 21  offline_timestamp                  19787 non-null  float64\n",
      " 22  incognito_mode                     46119 non-null  bool   \n",
      "dtypes: bool(4), float64(5), int64(1), object(13)\n",
      "memory usage: 6.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(Audio_data_exploration.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data types of each column:\n",
      "+----+-----------------------------------+-------------+\n",
      "|    | Column                            | Data Type   |\n",
      "|----+-----------------------------------+-------------|\n",
      "|  0 | ts                                | object      |\n",
      "|  1 | platform                          | object      |\n",
      "|  2 | ms_played                         | int64       |\n",
      "|  3 | conn_country                      | object      |\n",
      "|  4 | ip_addr                           | object      |\n",
      "|  5 | master_metadata_track_name        | object      |\n",
      "|  6 | master_metadata_album_artist_name | object      |\n",
      "|  7 | master_metadata_album_album_name  | object      |\n",
      "|  8 | spotify_track_uri                 | object      |\n",
      "|  9 | episode_name                      | object      |\n",
      "| 10 | episode_show_name                 | object      |\n",
      "| 11 | spotify_episode_uri               | object      |\n",
      "| 12 | audiobook_title                   | float64     |\n",
      "| 13 | audiobook_uri                     | float64     |\n",
      "| 14 | audiobook_chapter_uri             | float64     |\n",
      "| 15 | audiobook_chapter_title           | float64     |\n",
      "| 16 | reason_start                      | object      |\n",
      "| 17 | reason_end                        | object      |\n",
      "| 18 | shuffle                           | bool        |\n",
      "| 19 | skipped                           | bool        |\n",
      "| 20 | offline                           | bool        |\n",
      "| 21 | offline_timestamp                 | float64     |\n",
      "| 22 | incognito_mode                    | bool        |\n",
      "+----+-----------------------------------+-------------+\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nData types of each column:\")\n",
    "print(tabulate(pd.DataFrame(Audio_data_exploration.dtypes, columns=['Data Type']).reset_index(), headers=['Column', 'Data Type'], tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary statistics for numerical columns:\n",
      "+-------+------------------+-------------------+-----------------+-------------------------+---------------------------+---------------------+\n",
      "|       |        ms_played |   audiobook_title |   audiobook_uri |   audiobook_chapter_uri |   audiobook_chapter_title |   offline_timestamp |\n",
      "|-------+------------------+-------------------+-----------------+-------------------------+---------------------------+---------------------|\n",
      "| count |  46119           |                 0 |               0 |                       0 |                         0 |     19787           |\n",
      "| mean  | 114038           |               nan |             nan |                     nan |                       nan |         2.07407e+10 |\n",
      "| std   | 138295           |               nan |             nan |                     nan |                       nan |         1.75496e+11 |\n",
      "| min   |      0           |               nan |             nan |                     nan |                       nan |         1.66578e+09 |\n",
      "| 25%   |      0           |               nan |             nan |                     nan |                       nan |         1.69463e+09 |\n",
      "| 50%   |  99658           |               nan |             nan |                     nan |                       nan |         1.71659e+09 |\n",
      "| 75%   | 205430           |               nan |             nan |                     nan |                       nan |         1.72636e+09 |\n",
      "| max   |      9.73541e+06 |               nan |             nan |                     nan |                       nan |         1.66512e+12 |\n",
      "+-------+------------------+-------------------+-----------------+-------------------------+---------------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSummary statistics for numerical columns:\")\n",
    "print(tabulate(Audio_data_exploration.describe(), headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CHECKING FOR ANY NULL VALUES ACROSS THE COLUMNS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of non-null values in each column:\n",
      "+----+-----------------------------------+------------------+\n",
      "|    | Column                            |   Non-null Count |\n",
      "|----+-----------------------------------+------------------|\n",
      "|  0 | ts                                |            46119 |\n",
      "|  1 | platform                          |            46119 |\n",
      "|  2 | ms_played                         |            46119 |\n",
      "|  3 | conn_country                      |            46119 |\n",
      "|  4 | ip_addr                           |            46119 |\n",
      "|  5 | master_metadata_track_name        |            45838 |\n",
      "|  6 | master_metadata_album_artist_name |            45838 |\n",
      "|  7 | master_metadata_album_album_name  |            45838 |\n",
      "|  8 | spotify_track_uri                 |            45838 |\n",
      "|  9 | episode_name                      |              281 |\n",
      "| 10 | episode_show_name                 |              281 |\n",
      "| 11 | spotify_episode_uri               |              281 |\n",
      "| 12 | audiobook_title                   |                0 |\n",
      "| 13 | audiobook_uri                     |                0 |\n",
      "| 14 | audiobook_chapter_uri             |                0 |\n",
      "| 15 | audiobook_chapter_title           |                0 |\n",
      "| 16 | reason_start                      |            46119 |\n",
      "| 17 | reason_end                        |            46119 |\n",
      "| 18 | shuffle                           |            46119 |\n",
      "| 19 | skipped                           |            46119 |\n",
      "| 20 | offline                           |            46119 |\n",
      "| 21 | offline_timestamp                 |            19787 |\n",
      "| 22 | incognito_mode                    |            46119 |\n",
      "+----+-----------------------------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNumber of non-null values in each column:\")\n",
    "print(tabulate(Audio_data_exploration.count().reset_index(), headers=['Column', 'Non-null Count'], tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CHECKING FOR THE UNIQUE VALUES ACROSS ALL THE COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of unique values in each column:\n",
      "+----+-----------------------------------+----------------+\n",
      "|    | Column                            |   Unique Count |\n",
      "|----+-----------------------------------+----------------|\n",
      "|  0 | ts                                |          36040 |\n",
      "|  1 | platform                          |             12 |\n",
      "|  2 | ms_played                         |          15155 |\n",
      "|  3 | conn_country                      |              5 |\n",
      "|  4 | ip_addr                           |           2124 |\n",
      "|  5 | master_metadata_track_name        |           9426 |\n",
      "|  6 | master_metadata_album_artist_name |           3890 |\n",
      "|  7 | master_metadata_album_album_name  |           7385 |\n",
      "|  8 | spotify_track_uri                 |          10453 |\n",
      "|  9 | episode_name                      |            225 |\n",
      "| 10 | episode_show_name                 |             85 |\n",
      "| 11 | spotify_episode_uri               |            225 |\n",
      "| 12 | audiobook_title                   |              0 |\n",
      "| 13 | audiobook_uri                     |              0 |\n",
      "| 14 | audiobook_chapter_uri             |              0 |\n",
      "| 15 | audiobook_chapter_title           |              0 |\n",
      "| 16 | reason_start                      |              9 |\n",
      "| 17 | reason_end                        |             10 |\n",
      "| 18 | shuffle                           |              2 |\n",
      "| 19 | skipped                           |              2 |\n",
      "| 20 | offline                           |              2 |\n",
      "| 21 | offline_timestamp                 |          19641 |\n",
      "| 22 | incognito_mode                    |              2 |\n",
      "+----+-----------------------------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNumber of unique values in each column:\")\n",
    "print(tabulate(Audio_data_exploration.nunique().reset_index(), headers=['Column', 'Unique Count'], tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COLLECTING UNIQUE COUNTRY IN THE LIST OF ALL THE SONGS LISTENED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values in 'conn_country':\n",
      "+----+----------------+\n",
      "|    | conn_country   |\n",
      "|----+----------------|\n",
      "|  0 | IN             |\n",
      "|  1 | US             |\n",
      "|  2 | DE             |\n",
      "|  3 | GB             |\n",
      "|  4 | PR             |\n",
      "+----+----------------+\n"
     ]
    }
   ],
   "source": [
    "column_name = 'conn_country'\n",
    "print(f\"\\nUnique values in '{column_name}':\")\n",
    "print(tabulate(pd.DataFrame(Audio_data_exploration[column_name].unique(), columns=[column_name]), headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CHECKING FOR THE VALUE ASSOCIATE WITH REASON_END COLUMN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values in a 'reason_end':\n",
      "+----+------------------------------+\n",
      "|    | reason_end                   |\n",
      "|----+------------------------------|\n",
      "|  0 | trackdone                    |\n",
      "|  1 | logout                       |\n",
      "|  2 | endplay                      |\n",
      "|  3 | unexpected-exit-while-paused |\n",
      "|  4 | fwdbtn                       |\n",
      "|  5 | unknown                      |\n",
      "|  6 | remote                       |\n",
      "|  7 | backbtn                      |\n",
      "|  8 | trackerror                   |\n",
      "|  9 | unexpected-exit              |\n",
      "+----+------------------------------+\n"
     ]
    }
   ],
   "source": [
    "column_name = 'reason_end'\n",
    "print(f\"\\nUnique values in a '{column_name}':\")\n",
    "print(tabulate(pd.DataFrame(Audio_data_exploration[column_name].unique(), columns=[column_name]),headers='keys',tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CHECKING FOR THE VALUE ASSOCIATE WITH REASON_START COLUMN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values in a 'reason_start':\n",
      "+----+----------------+\n",
      "|    | reason_start   |\n",
      "|----+----------------|\n",
      "|  0 | clickrow       |\n",
      "|  1 | trackdone      |\n",
      "|  2 | appload        |\n",
      "|  3 | playbtn        |\n",
      "|  4 | fwdbtn         |\n",
      "|  5 | trackerror     |\n",
      "|  6 | remote         |\n",
      "|  7 | backbtn        |\n",
      "|  8 | unknown        |\n",
      "+----+----------------+\n"
     ]
    }
   ],
   "source": [
    "column_name = 'reason_start'\n",
    "print(f\"\\nUnique values in a '{column_name}':\")\n",
    "print(tabulate(pd.DataFrame(Audio_data_exploration[column_name].unique(), columns=[column_name]),headers='keys',tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Number of zero entries in the master_metadata(Track_name, Album_Artist_Name,Album_Album_Name\n",
      "281\n",
      "+------+----------------------+------------------------------------------+-------------+----------------+----------------+------------------------------+-------------------------------------+------------------------------------+---------------------+---------------------------------------------------------------------------------------------------------------+-------------------------------+----------------------------------------+-------------------+-----------------+-------------------------+---------------------------+----------------+--------------+-----------+-----------+-----------+---------------------+------------------+\n",
      "|      | ts                   | platform                                 |   ms_played | conn_country   | ip_addr        | master_metadata_track_name   | master_metadata_album_artist_name   | master_metadata_album_album_name   | spotify_track_uri   | episode_name                                                                                                  | episode_show_name             | spotify_episode_uri                    |   audiobook_title |   audiobook_uri |   audiobook_chapter_uri |   audiobook_chapter_title | reason_start   | reason_end   | shuffle   | skipped   | offline   |   offline_timestamp | incognito_mode   |\n",
      "|------+----------------------+------------------------------------------+-------------+----------------+----------------+------------------------------+-------------------------------------+------------------------------------+---------------------+---------------------------------------------------------------------------------------------------------------+-------------------------------+----------------------------------------+-------------------+-----------------+-------------------------+---------------------------+----------------+--------------+-----------+-----------+-----------+---------------------+------------------|\n",
      "| 1241 | 2020-10-28T17:27:46Z | Android OS 10 API 29 (samsung, SM-M307F) |       22269 | IN             | 157.46.96.248  |                              |                                     |                                    |                     | Exercise and Alcohol                                                                                          | Get Fit With Biglee           | spotify:episode:1NQibItXhXp2OqO8IUmcdZ |               nan |             nan |                     nan |                       nan | clickrow       | endplay      | False     | False     | False     |                 nan | False            |\n",
      "| 1328 | 2020-10-31T11:44:36Z | Android OS 10 API 29 (samsung, SM-M307F) |      119608 | IN             | 106.217.2.233  |                              |                                     |                                    |                     | Motivational Podcasts | KEEP GOING - Best Motivational Video Speeches Compilation (Most Eye Opening Speeches) | Motivational Speeches         | spotify:episode:14JuiW57XEszH85eIwnjNW |               nan |             nan |                     nan |                       nan | clickrow       | endplay      | False     | False     | False     |                 nan | False            |\n",
      "| 2345 | 2020-12-01T17:16:36Z | Android OS 10 API 29 (samsung, SM-M307F) |       31809 | IN             | 106.217.18.175 |                              |                                     |                                    |                     | How going out for a day feels like? (ft. Srivi)                                                               | Into The Mind Of An Introvert | spotify:episode:3aJIt9wAVCSgxbUHW1hEQY |               nan |             nan |                     nan |                       nan | clickrow       | endplay      | False     | False     | False     |                 nan | False            |\n",
      "| 2756 | 2020-12-16T09:56:28Z | Android OS 10 API 29 (samsung, SM-M307F) |      345917 | IN             | 157.49.222.110 |                              |                                     |                                    |                     | Mindset: The New Psychology of Success by Carol S. Dweck | Episode 4 |                                        | The Audiobooks Podcast        | spotify:episode:0Z8t56BLqH7DDP7f6acsTt |               nan |             nan |                     nan |                       nan | clickrow       | endplay      | False     | False     | False     |                 nan | False            |\n",
      "| 2757 | 2020-12-16T09:56:53Z | Android OS 10 API 29 (samsung, SM-M307F) |       17156 | IN             | 157.49.222.110 |                              |                                     |                                    |                     | 3 Strategies Confident People Use to Overcome Their Ego                                                       | On Purpose with Jay Shetty    | spotify:episode:3vGlG5Z0BxF44IsB6qgbzz |               nan |             nan |                     nan |                       nan | clickrow       | endplay      | False     | False     | False     |                 nan | False            |\n",
      "+------+----------------------+------------------------------------------+-------------+----------------+----------------+------------------------------+-------------------------------------+------------------------------------+---------------------+---------------------------------------------------------------------------------------------------------------+-------------------------------+----------------------------------------+-------------------+-----------------+-------------------------+---------------------------+----------------+--------------+-----------+-----------+-----------+---------------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Number of zero entries in the master_metadata(Track_name, Album_Artist_Name,Album_Album_Name\")\n",
    "\n",
    "filtered_zero_entries = Audio_data_exploration[(Audio_data_exploration[\"master_metadata_track_name\"].isnull()) & (Audio_data_exploration[\"master_metadata_album_artist_name\"].isnull()) & (Audio_data_exploration[\"master_metadata_album_album_name\"].isnull())]\n",
    "print(len(filtered_zero_entries))\n",
    "\n",
    "print(tabulate(filtered_zero_entries.head(), headers =\"keys\" , tablefmt =\"psql\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Counts for each combination of null and non-null values:\n",
      "+----+------------------------------------+---------+\n",
      "|    | Combination                        |   Count |\n",
      "|----+------------------------------------+---------|\n",
      "|  0 | Total Number of Records            |   46119 |\n",
      "|  1 | All Specified columns are not null |   45838 |\n",
      "|  2 | Difference Count                   |     281 |\n",
      "+----+------------------------------------+---------+\n"
     ]
    }
   ],
   "source": [
    "columns = ['master_metadata_track_name', 'master_metadata_album_artist_name', 'master_metadata_album_album_name']\n",
    "\n",
    "# Initialize a dictionary to hold the counts for each combination\n",
    "combination_counts = {}\n",
    "\n",
    "# Check all combinations of null and non-null values for the specified columns\n",
    "#  for col1 in columns:\n",
    "#     for col2 in columns:\n",
    "#         for col3 in columns:\n",
    "#             if col1 != col2 and col1 != col3 and col2 != col3:\n",
    "#                 # Count records where col1 is null and col2 and col3 are not null\n",
    "#                 count_null_col1 = Audio_data_exploration[Audio_data_exploration[col1].isnull() & Audio_data_exploration[col2].notnull() & Audio_data_exploration[col3].notnull()].shape[0]\n",
    "#                 combination_counts[f\"{col1} is null and {col2} and {col3} are not null\"] = count_null_col1\n",
    "                \n",
    "#                 # Count records where col1 is not null and col2 is null and col3 is not null\n",
    "#                 count_null_col2 = Audio_data_exploration[Audio_data_exploration[col1].notnull() & Audio_data_exploration[col2].isnull() & Audio_data_exploration[col3].notnull()].shape[0]\n",
    "#                 combination_counts[f\"{col2} is null and {col1} and {col3} are not null\"] = count_null_col2\n",
    "                \n",
    "#                 # Count records where col1 and col2 are not null and col3 is null\n",
    "#                 count_null_col3 = Audio_data_exploration[Audio_data_exploration[col1].notnull() & Audio_data_exploration[col2].notnull() & Audio_data_exploration[col3].isnull()].shape[0]\n",
    "#                 combination_counts[f\"{col3} is null and {col1} and {col2} are not null\"] = count_null_col3\n",
    "\n",
    "\n",
    "# Count records where all specified columns are not null\n",
    "count_total_record_not_null = len(Audio_data_exploration)\n",
    "count_all_not_null = Audio_data_exploration[Audio_data_exploration[columns].notnull().all(axis=1)].shape[0]\n",
    "combination_counts[f\"Total Number of Records\"] = count_total_record_not_null\n",
    "combination_counts[f\"All Specified columns are not null\"] = count_all_not_null\n",
    "\n",
    "Difference_Count = count_total_record_not_null - count_all_not_null\n",
    "combination_counts['Difference Count'] = Difference_Count\n",
    "\n",
    "# Display the counts for each combination\n",
    "print(\"\\nCounts for each combination of null and non-null values:\")\n",
    "print(tabulate(pd.DataFrame(list(combination_counts.items()), columns=['Combination', 'Count']), headers='keys', tablefmt='psql'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------------------+---------+\n",
      "|    | Combination                |   Count |\n",
      "|----+----------------------------+---------|\n",
      "|  0 | Total Count of Android     |   11401 |\n",
      "|  1 | Total Count of Android Tab |    5250 |\n",
      "|  2 | total_count_android_ios    |   13865 |\n",
      "+----+----------------------------+---------+\n"
     ]
    }
   ],
   "source": [
    "combined_count ={}\n",
    "\n",
    "total_count_android = Audio_data_exploration[Audio_data_exploration['platform'] == 'Android OS 10 API 29 (samsung, SM-M307F)']\n",
    "total_count_android_tab = Audio_data_exploration[Audio_data_exploration['platform'] == 'android']\n",
    "total_count_android_ios = Audio_data_exploration[Audio_data_exploration['platform'] == 'ios']\n",
    "\n",
    "combined_count['Total Count of Android'] = len(total_count_android)\n",
    "combined_count['Total Count of Android Tab'] = len(total_count_android_tab)\n",
    "combined_count['total_count_android_ios'] = len(total_count_android_ios)\n",
    "\n",
    "# print(len(total_count_android))\n",
    "# print(len(total_count_android_tab))\n",
    "# print(len(total_count_android_ios))\n",
    "\n",
    "print(tabulate(pd.DataFrame(list(combined_count.items()), columns=['Combination', 'Count']), headers='keys', tablefmt='psql'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+---------+\n",
      "|    | Combination      |   Count |\n",
      "|----+------------------+---------|\n",
      "|  0 | Country_count_US |   14527 |\n",
      "|  1 | Country_count_IN |   31562 |\n",
      "|  2 | Country_count_DE |      12 |\n",
      "|  3 | Country_count_GB |       7 |\n",
      "|  4 | Country_count_PR |      11 |\n",
      "+----+------------------+---------+\n"
     ]
    }
   ],
   "source": [
    "combined_count ={}\n",
    "\n",
    "Country_count_US = Audio_data_exploration[Audio_data_exploration['conn_country'] == 'US']\n",
    "Country_count_IN = Audio_data_exploration[Audio_data_exploration['conn_country'] == 'IN']\n",
    "Country_count_DE= Audio_data_exploration[Audio_data_exploration['conn_country'] == 'DE']\n",
    "Country_count_GB = Audio_data_exploration[Audio_data_exploration['conn_country'] == 'GB']\n",
    "Country_count_PR = Audio_data_exploration[Audio_data_exploration['conn_country'] == 'PR']\n",
    "\n",
    "combined_count['Country_count_US'] = len(Country_count_US)\n",
    "combined_count['Country_count_IN'] = len(Country_count_IN)\n",
    "combined_count['Country_count_DE'] = len(Country_count_DE)\n",
    "combined_count['Country_count_GB'] = len(Country_count_GB)\n",
    "combined_count['Country_count_PR'] = len(Country_count_PR)\n",
    "\n",
    "# print(len(total_count_android))\n",
    "# print(len(total_count_android_tab))\n",
    "# print(len(total_count_android_ios))\n",
    "\n",
    "print(tabulate(pd.DataFrame(list(combined_count.items()), columns=['Combination', 'Count']), headers='keys', tablefmt='psql'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in 'offline_timestamp' when 'offline' is true: 0\n",
      "\n",
      "First few rows of the filtered DataFrame where 'offline' is true:\n",
      "+------+----------------------+------------------------------------------+-------------+----------------+----------------+------------------------------------------+-------------------------------------+----------------------------------------+--------------------------------------+----------------+---------------------+-----------------------+-------------------+-----------------+-------------------------+---------------------------+----------------+--------------+-----------+-----------+-----------+---------------------+------------------+\n",
      "|      | ts                   | platform                                 |   ms_played | conn_country   | ip_addr        | master_metadata_track_name               | master_metadata_album_artist_name   | master_metadata_album_album_name       | spotify_track_uri                    | episode_name   | episode_show_name   | spotify_episode_uri   |   audiobook_title |   audiobook_uri |   audiobook_chapter_uri |   audiobook_chapter_title | reason_start   | reason_end   | shuffle   | skipped   | offline   |   offline_timestamp | incognito_mode   |\n",
      "|------+----------------------+------------------------------------------+-------------+----------------+----------------+------------------------------------------+-------------------------------------+----------------------------------------+--------------------------------------+----------------+---------------------+-----------------------+-------------------+-----------------+-------------------------+---------------------------+----------------+--------------+-----------+-----------+-----------+---------------------+------------------|\n",
      "| 1719 | 2020-11-16T01:13:49Z | Android OS 10 API 29 (samsung, SM-M307F) |      171374 | IN             | 106.217.2.206  | Savage Love (Laxed - Siren Beat)         | Jawsh 685                           | Savage Love (Laxed - Siren Beat)       | spotify:track:1xQ6trAsedVPCdbtDAmk0c |                |                     |                       |               nan |             nan |                     nan |                       nan | trackdone      | trackdone    | False     | False     | True      |         1.60549e+12 | False            |\n",
      "| 2306 | 2020-11-30T12:39:43Z | Android OS 10 API 29 (samsung, SM-M307F) |       34990 | IN             | 157.49.250.52  | All Falls Down (feat. Juliander)         | Alan Walker                         | Different World                        | spotify:track:1HvCFAUIWQsWV9zud3UhDl |                |                     |                       |               nan |             nan |                     nan |                       nan | trackdone      | endplay      | False     | False     | True      |         1.60674e+12 | False            |\n",
      "| 2954 | 2020-12-26T16:44:54Z | Android OS 10 API 29 (samsung, SM-M307F) |      115853 | IN             | 157.51.154.143 | A Life Full of Love Theme - Instrumental | Anirudh Ravichander                 | 3 (Original Motion Picture Soundtrack) | spotify:track:5o0cR4FzBPvSE7831sBNvq |                |                     |                       |               nan |             nan |                     nan |                       nan | trackdone      | trackdone    | False     | False     | True      |         1.609e+12   | False            |\n",
      "| 3573 | 2021-01-30T18:28:39Z | Android OS 10 API 29 (samsung, SM-M307F) |        2193 | IN             | 106.217.2.213  | Come on Girls - The Celebration of Love  | Anirudh Ravichander                 | 3 (Original Motion Picture Soundtrack) | spotify:track:2mP9sA0wyHwybuJKjQ16AV |                |                     |                       |               nan |             nan |                     nan |                       nan | fwdbtn         | fwdbtn       | False     | False     | True      |         1.61203e+12 | False            |\n",
      "| 3574 | 2021-01-30T18:28:39Z | Android OS 10 API 29 (samsung, SM-M307F) |        9209 | IN             | 106.217.2.213  | Come on Girls - The Celebration of Love  | Anirudh Ravichander                 | 3 (Original Motion Picture Soundtrack) | spotify:track:2mP9sA0wyHwybuJKjQ16AV |                |                     |                       |               nan |             nan |                     nan |                       nan | trackdone      | fwdbtn       | False     | False     | True      |         1.61203e+12 | False            |\n",
      "+------+----------------------+------------------------------------------+-------------+----------------+----------------+------------------------------------------+-------------------------------------+----------------------------------------+--------------------------------------+----------------+---------------------+-----------------------+-------------------+-----------------+-------------------------+---------------------------+----------------+--------------+-----------+-----------+-----------+---------------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Filter records where 'offline' is true\n",
    "offline_true_data = Audio_data_exploration[Audio_data_exploration['offline'] == True]\n",
    "\n",
    "# Count the number of null values in the 'offline_timestamp' column\n",
    "null_offline_timestamp_count = offline_true_data['offline_timestamp'].isnull().sum()\n",
    "\n",
    "# Display the count\n",
    "print(f\"Number of null values in 'offline_timestamp' when 'offline' is true: {null_offline_timestamp_count}\")\n",
    "\n",
    "# Display the first few rows of the filtered DataFrame in table format\n",
    "print(\"\\nFirst few rows of the filtered DataFrame where 'offline' is true:\")\n",
    "print(tabulate(offline_true_data.head(), headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Define the path to the existing JSON file\n",
    "json_file_path = 'Streaming_History_Audio_2020-2025.json'\n",
    "\n",
    "# Read the JSON file into a pandas DataFrame\n",
    "Audio_data_exploration = pd.read_json(json_file_path)\n",
    "\n",
    "# Convert the 'ts' column to datetime format with UTC timezone\n",
    "Audio_data_exploration['ts'] = pd.to_datetime(Audio_data_exploration['ts'], utc=True)\n",
    "\n",
    "# Define the cutoff date with UTC timezone\n",
    "cutoff_date = pd.to_datetime('2024-01-15').tz_localize('UTC')\n",
    "\n",
    "# Filter records after the cutoff date\n",
    "filtered_data = Audio_data_exploration[Audio_data_exploration['ts'] > cutoff_date]\n",
    "\n",
    "# Filter records where conn_country is 'IN' after the cutoff date\n",
    "filtered_in_data = filtered_data[filtered_data['conn_country'] == 'IN']\n",
    "\n",
    "# Count the number of records for 'IN' after the cutoff date\n",
    "count_in_after_cutoff = filtered_in_data.shape[0]\n",
    "\n",
    "# Display the unique platforms associated with these records\n",
    "unique_platforms = filtered_in_data['platform'].unique()\n",
    "platform_counts = filtered_in_data['platform'].value_counts()\n",
    "\n",
    "# Display the counts and unique platforms\n",
    "print(f\"\\nNumber of records for IN after {cutoff_date}: {count_in_after_cutoff}\")\n",
    "print(\"\\nUnique platforms associated with these records:\")\n",
    "print(tabulate(pd.DataFrame(unique_platforms, columns=['Platform']), headers='keys', tablefmt='psql'))\n",
    "\n",
    "print(\"\\nPlatform counts associated with these records:\")\n",
    "print(tabulate(platform_counts.reset_index(), headers=['Platform', 'Count'], tablefmt='psql'))\n",
    "\n",
    "# Display the first few rows of the filtered DataFrame in table format\n",
    "print(\"\\nFirst few rows of the filtered DataFrame for IN:\")\n",
    "print(tabulate(filtered_in_data.head(), headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHANGING THE DATA LANSACAPE OF THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "platform\n",
      "ANDROID     16651\n",
      "WINDOWS     15412\n",
      "IOS         13865\n",
      "LINUX         135\n",
      "SMART_TV       32\n",
      "OTHERS         24\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "json_file_path = 'c:/Users/mkalw/OneDrive - University at Buffalo/Project Work/Project/Spotify/my_spotify_data/Spotify Extended Streaming History/Streaming_History_Audio_2020-2025.json'\n",
    "\n",
    "Audio_Data_Frame_202_2025 = pd.read_json(json_file_path)\n",
    "\n",
    "#print(tabulate(Audio_Data_Frame_202_2025.head(), headers ='keys', tablefmt ='psql'))\n",
    "#print(len(Audio_Data_Frame_202_2025))\n",
    "\n",
    "platform_standarisation  = {\n",
    "    'Linux [x86-64 0]' :'LINUX'  ,                                                          \n",
    "    'Android OS 10 API 29 (samsung, SM-M307F)'   : 'ANDROID',                                 \n",
    "    'Windows 10 (X.X.X.X; x64; AppX)'          : 'WINDOWS',                                \n",
    "    'Windows 10 (X.X.X.X; x64; AppX)'          : 'WINDOWS',                                 \n",
    "    'Windows 10 (X.X.X.X; x64)'                : 'WINDOWS',                                 \n",
    "    'Windows 10 (10.0.19043; x64)'                : 'WINDOWS',                                 \n",
    "    'Partner android_tv Droidlogic;SMART_TV;756a522d9f1648b89e76e80be654456a;;tpapi' : 'SMART_TV',\n",
    "    'android'          : 'ANDROID'  ,                                                       \n",
    "    'windows'          : 'WINDOWS'    ,                                                       \n",
    "    'ios'              : 'IOS',                                                             \n",
    "    'playstation'       : 'OTHERS' ,                                                           \n",
    "    'not_applicable'    : 'OTHERS'        \t\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "# # Identify platform names that are not in the platform_standarisation dictionary\n",
    "# unique_platforms_before = Audio_Data_Frame_202_2025['platform'].unique()\n",
    "# unmapped_platforms = [platform for platform in unique_platforms_before if platform not in platform_standarisation]\n",
    "\n",
    "\n",
    "# nan_count_before = Audio_Data_Frame_202_2025['platform'].isnull().sum()\n",
    "# print(f\"Number of NaN values in 'platform' column before mapping: {nan_count_before}\")\n",
    "\n",
    "Audio_Data_Frame_202_2025['platform'] = Audio_Data_Frame_202_2025['platform'].map(platform_standarisation)\n",
    "\n",
    "# nan_count_after = Audio_Data_Frame_202_2025['platform'].isnull().sum()\n",
    "# print(f\"Number of NaN values in 'platform' column after mapping: {nan_count_after}\")\n",
    "\n",
    "print(Audio_Data_Frame_202_2025['platform'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trackdone' 'logout' 'endplay' 'unexpected-exit-while-paused' 'fwdbtn'\n",
      " 'unknown' 'remote' 'backbtn' 'trackerror' 'unexpected-exit']\n"
     ]
    }
   ],
   "source": [
    "reason_end_standarisation = {\n",
    " 'trackdone' \t :                 'TRACKDONE',\n",
    " 'logout'\t      :'LOGOUT' ,\n",
    " 'endplay'\t       :             'ENDPLAY' ,\n",
    " 'unexpected-exit-while-paused':\t 'EXIT',\n",
    " 'fwdbtn' :\t 'FWDBTN',\n",
    " 'unknown' \t: 'UNKNOWN' ,\n",
    " 'remote' \t :'REMOTE',\n",
    " 'backbtn' :\t 'BACKBTN',\n",
    " 'trackerror' :\t 'TRACKERROR' ,\n",
    " 'unexpected-exit': \t 'EXIT' \n",
    "}\n",
    "\n",
    "unique_reason_before = Audio_Data_Frame_202_2025['reason_end'].unique()\n",
    "print(unique_reason_before)\n",
    "unmapped_reason = [reason for reason in unique_reason_before if reason not in reason_end_standarisation]\n",
    "\n",
    "#print(unmapped_reason)\n",
    "\n",
    "Audio_Data_Frame_202_2025['reason_end'] = Audio_Data_Frame_202_2025['reason_end'].map(reason_end_standarisation)\n",
    "\n",
    "#print(Audio_Data_Frame_202_2025['reason_end'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+---------+\n",
      "|    | Platform   |   Count |\n",
      "|----+------------+---------|\n",
      "|  0 | TRACKDONE  |   22384 |\n",
      "|  1 | FWDBTN     |   16413 |\n",
      "|  2 | ENDPLAY    |    4414 |\n",
      "|  3 | LOGOUT     |    1554 |\n",
      "|  4 | EXIT       |     999 |\n",
      "|  5 | BACKBTN    |     221 |\n",
      "|  6 | REMOTE     |      72 |\n",
      "|  7 | UNKNOWN    |      52 |\n",
      "|  8 | TRACKERROR |      10 |\n",
      "+----+------------+---------+\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(Audio_Data_Frame_202_2025['reason_end'].value_counts().reset_index(), headers=['Platform', 'Count'], tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IN' 'US' 'DE' 'GB' 'PR']\n"
     ]
    }
   ],
   "source": [
    "Country_Name_standarisation = {\n",
    "     'IN'\t:\t 'INDIA'\t,\n",
    " 'US'\t:\t 'UNITED STATES'\t,\n",
    " 'DE'\t:\t 'GERMANY'\t,\n",
    " 'GB'\t:\t 'UNITED KINGDOM'\t,\n",
    " 'PR' \t:\t 'PUERTO RICO'\t, \t\n",
    "\n",
    " }\n",
    "\n",
    "unique_country = Audio_Data_Frame_202_2025['conn_country'].unique()\n",
    "print(unique_country)\n",
    "unmapped_country = [country for country in unique_country if country not in Country_Name_standarisation]\n",
    "\n",
    "Audio_Data_Frame_202_2025['conn_country'] = Audio_Data_Frame_202_2025['conn_country'].map(Country_Name_standarisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------+---------+\n",
      "|    | Platform       |   Count |\n",
      "|----+----------------+---------|\n",
      "|  0 | INDIA          |   31562 |\n",
      "|  1 | UNITED STATES  |   14527 |\n",
      "|  2 | GERMANY        |      12 |\n",
      "|  3 | PUERTO RICO    |      11 |\n",
      "|  4 | UNITED KINGDOM |       7 |\n",
      "+----+----------------+---------+\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(Audio_Data_Frame_202_2025['conn_country'].value_counts().reset_index(), headers=['Platform', 'Count'], tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clickrow' 'trackdone' 'appload' 'playbtn' 'fwdbtn' 'trackerror' 'remote'\n",
      " 'backbtn' 'unknown']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "reason_start_standarisation = {\n",
    " 'clickrow' \t :                 'CLICKROW',\n",
    " 'trackdone'\t      :'TRACKDONE' ,\n",
    " 'appload'\t       :             'APPLOAD' ,\n",
    " 'playbtn':\t 'PLAYBTN',\n",
    " 'fwdbtn' :\t 'FWDBTN',\n",
    " 'trackerror' \t: 'TRACKERROR' ,\n",
    " 'remote' \t :'REMOTE',\n",
    " 'backbtn' :\t 'BACKBTN',\n",
    " 'unknown' :\t 'UNKNOWN' , \n",
    "}\n",
    "\n",
    "unique_reason_before = Audio_Data_Frame_202_2025['reason_start'].unique()\n",
    "print(unique_reason_before)\n",
    "unmapped_reason = [reason for reason in unique_reason_before if reason not in reason_start_standarisation]\n",
    "\n",
    "print(unmapped_reason)\n",
    "\n",
    "Audio_Data_Frame_202_2025['reason_start'] = Audio_Data_Frame_202_2025['reason_start'].map(reason_start_standarisation)\n",
    "\n",
    "#print(Audio_Data_Frame_202_2025['reason_end'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+---------+\n",
      "|    | Platform   |   Count |\n",
      "|----+------------+---------|\n",
      "|  0 | TRACKDONE  |   22652 |\n",
      "|  1 | FWDBTN     |   16390 |\n",
      "|  2 | CLICKROW   |    4952 |\n",
      "|  3 | PLAYBTN    |     963 |\n",
      "|  4 | APPLOAD    |     642 |\n",
      "|  5 | BACKBTN    |     226 |\n",
      "|  6 | TRACKERROR |     165 |\n",
      "|  7 | REMOTE     |     112 |\n",
      "|  8 | UNKNOWN    |      17 |\n",
      "+----+------------+---------+\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(Audio_Data_Frame_202_2025['reason_start'].value_counts().reset_index(), headers=['Platform', 'Count'], tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "## droppping the sensitive information and unwanted columns\n",
    "\n",
    "Audio_Data_Frame_202_2025.drop(['ip_addr', 'incognito_mode', 'offline_timestamp'], axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the updated DataFrame with 'minutes_played' column:\n",
      "+----+----------------------+------------+----------------+------------------+------------------------------+-------------------------------------+------------------------------------+--------------------------------------+----------------+---------------------+-----------------------+-------------------+-----------------+-------------------------+---------------------------+----------------+--------------+-----------+-----------+-----------+\n",
      "|    | ts                   | platform   | conn_country   |   minutes_played | master_metadata_track_name   | master_metadata_album_artist_name   | master_metadata_album_album_name   | spotify_track_uri                    | episode_name   | episode_show_name   | spotify_episode_uri   |   audiobook_title |   audiobook_uri |   audiobook_chapter_uri |   audiobook_chapter_title | reason_start   | reason_end   | shuffle   | skipped   | offline   |\n",
      "|----+----------------------+------------+----------------+------------------+------------------------------+-------------------------------------+------------------------------------+--------------------------------------+----------------+---------------------+-----------------------+-------------------+-----------------+-------------------------+---------------------------+----------------+--------------+-----------+-----------+-----------|\n",
      "|  0 | 2020-08-05T08:53:20Z | LINUX      | INDIA          |          3.00698 | Undo My Heart                | Karen Harding                       | Undo My Heart                      | spotify:track:4IKa5EKTmhKvV1wuTJf9Eq |                |                     |                       |               nan |             nan |                     nan |                       nan | CLICKROW       | TRACKDONE    | False     | False     | False     |\n",
      "|  1 | 2020-08-05T08:56:50Z | LINUX      | INDIA          |          3.49333 | HEART ATTACK (feat. lau.ra)  | BRONSON                             | HEART ATTACK / VAULTS              | spotify:track:3xrSAFB6cXBHwLylbCP4sr |                |                     |                       |               nan |             nan |                     nan |                       nan | TRACKDONE      | TRACKDONE    | False     | False     | False     |\n",
      "|  2 | 2020-08-12T09:06:32Z | LINUX      | INDIA          |          1.85368 | Someday                      | Kygo                                | Golden Hour                        | spotify:track:73h6Ma5QhBFrshEN2CTevS |                |                     |                       |               nan |             nan |                     nan |                       nan | TRACKDONE      | LOGOUT       | False     | False     | False     |\n",
      "|  3 | 2020-08-12T09:08:46Z | LINUX      | INDIA          |          1.87148 | Someday                      | Kygo                                | Golden Hour                        | spotify:track:73h6Ma5QhBFrshEN2CTevS |                |                     |                       |               nan |             nan |                     nan |                       nan | APPLOAD        | TRACKDONE    | False     | False     | False     |\n",
      "|  4 | 2020-08-12T09:18:47Z | LINUX      | INDIA          |          3.37442 | Only Us                      | Kygo                                | Golden Hour                        | spotify:track:1SQbUQ8w21CxAhvkZvHN0u |                |                     |                       |               nan |             nan |                     nan |                       nan | TRACKDONE      | TRACKDONE    | False     | False     | False     |\n",
      "+----+----------------------+------------+----------------+------------------+------------------------------+-------------------------------------+------------------------------------+--------------------------------------+----------------+---------------------+-----------------------+-------------------+-----------------+-------------------------+---------------------------+----------------+--------------+-----------+-----------+-----------+\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46119 entries, 0 to 46118\n",
      "Data columns (total 20 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   ts                                 46119 non-null  object \n",
      " 1   platform                           46119 non-null  object \n",
      " 2   conn_country                       46119 non-null  object \n",
      " 3   minutes_played                     46119 non-null  float64\n",
      " 4   master_metadata_track_name         45838 non-null  object \n",
      " 5   master_metadata_album_artist_name  45838 non-null  object \n",
      " 6   master_metadata_album_album_name   45838 non-null  object \n",
      " 7   spotify_track_uri                  45838 non-null  object \n",
      " 8   episode_name                       281 non-null    object \n",
      " 9   episode_show_name                  281 non-null    object \n",
      " 10  spotify_episode_uri                281 non-null    object \n",
      " 11  audiobook_title                    0 non-null      float64\n",
      " 12  audiobook_uri                      0 non-null      float64\n",
      " 13  audiobook_chapter_uri              0 non-null      float64\n",
      " 14  audiobook_chapter_title            0 non-null      float64\n",
      " 15  reason_start                       46119 non-null  object \n",
      " 16  reason_end                         46119 non-null  object \n",
      " 17  shuffle                            46119 non-null  bool   \n",
      " 18  skipped                            46119 non-null  bool   \n",
      " 19  offline                            46119 non-null  bool   \n",
      "dtypes: bool(3), float64(5), object(12)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "Audio_Data_Frame_202_2025['minutes_played'] = Audio_Data_Frame_202_2025['ms_played'] / 60000\n",
    "\n",
    "Audio_Data_Frame_202_2025.drop(['ms_played'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "cols = list(Audio_Data_Frame_202_2025.columns)\n",
    "cols.insert(3, cols.pop(cols.index('minutes_played')))\n",
    "Audio_Data_Frame_202_2025 = Audio_Data_Frame_202_2025[cols]\n",
    "\n",
    "\n",
    "print(\"First few rows of the updated DataFrame with 'minutes_played' column:\")\n",
    "print(tabulate(Audio_Data_Frame_202_2025.head(), headers='keys', tablefmt='psql'))\n",
    "\n",
    "Audio_Data_Frame_202_2025.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the updated DataFrame with 'minutes_played' column:\n",
      "+----+----------------------+------------+----------------+------------------+------------------------------+-------------------------------------+------------------------------------+--------------------------------------+----------------+---------------------+-----------------------+-------------------+-----------------+-------------------------+---------------------------+----------------+--------------+-----------+-----------+-----------+\n",
      "|    | ts                   | platform   | conn_country   |   minutes_played | master_metadata_track_name   | master_metadata_album_artist_name   | master_metadata_album_album_name   | spotify_track_uri                    | episode_name   | episode_show_name   | spotify_episode_uri   |   audiobook_title |   audiobook_uri |   audiobook_chapter_uri |   audiobook_chapter_title | reason_start   | reason_end   | shuffle   | skipped   | offline   |\n",
      "|----+----------------------+------------+----------------+------------------+------------------------------+-------------------------------------+------------------------------------+--------------------------------------+----------------+---------------------+-----------------------+-------------------+-----------------+-------------------------+---------------------------+----------------+--------------+-----------+-----------+-----------|\n",
      "|  0 | 2020-08-05T08:53:20Z | LINUX      | INDIA          |              3   | Undo My Heart                | Karen Harding                       | Undo My Heart                      | spotify:track:4IKa5EKTmhKvV1wuTJf9Eq |                |                     |                       |               nan |             nan |                     nan |                       nan | CLICKROW       | TRACKDONE    | False     | False     | False     |\n",
      "|  1 | 2020-08-05T08:56:50Z | LINUX      | INDIA          |              3.5 | HEART ATTACK (feat. lau.ra)  | BRONSON                             | HEART ATTACK / VAULTS              | spotify:track:3xrSAFB6cXBHwLylbCP4sr |                |                     |                       |               nan |             nan |                     nan |                       nan | TRACKDONE      | TRACKDONE    | False     | False     | False     |\n",
      "|  2 | 2020-08-12T09:06:32Z | LINUX      | INDIA          |              1.9 | Someday                      | Kygo                                | Golden Hour                        | spotify:track:73h6Ma5QhBFrshEN2CTevS |                |                     |                       |               nan |             nan |                     nan |                       nan | TRACKDONE      | LOGOUT       | False     | False     | False     |\n",
      "|  3 | 2020-08-12T09:08:46Z | LINUX      | INDIA          |              1.9 | Someday                      | Kygo                                | Golden Hour                        | spotify:track:73h6Ma5QhBFrshEN2CTevS |                |                     |                       |               nan |             nan |                     nan |                       nan | APPLOAD        | TRACKDONE    | False     | False     | False     |\n",
      "|  4 | 2020-08-12T09:18:47Z | LINUX      | INDIA          |              3.4 | Only Us                      | Kygo                                | Golden Hour                        | spotify:track:1SQbUQ8w21CxAhvkZvHN0u |                |                     |                       |               nan |             nan |                     nan |                       nan | TRACKDONE      | TRACKDONE    | False     | False     | False     |\n",
      "+----+----------------------+------------+----------------+------------------+------------------------------+-------------------------------------+------------------------------------+--------------------------------------+----------------+---------------------+-----------------------+-------------------+-----------------+-------------------------+---------------------------+----------------+--------------+-----------+-----------+-----------+\n"
     ]
    }
   ],
   "source": [
    "# Round of the minutes_played column to 1 decimal place\n",
    "\n",
    "Audio_Data_Frame_202_2025['minutes_played'] = Audio_Data_Frame_202_2025['minutes_played'].round(1)\n",
    "\n",
    "print(\"First few rows of the updated DataFrame with 'minutes_played' column:\")\n",
    "print(tabulate(Audio_Data_Frame_202_2025.head(), headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       utc_time_zone_ts platform conn_country  minutes_played  \\\n",
      "0  2020-08-05T08:53:20Z    LINUX        INDIA             3.0   \n",
      "1  2020-08-05T08:56:50Z    LINUX        INDIA             3.5   \n",
      "2  2020-08-12T09:06:32Z    LINUX        INDIA             1.9   \n",
      "3  2020-08-12T09:08:46Z    LINUX        INDIA             1.9   \n",
      "4  2020-08-12T09:18:47Z    LINUX        INDIA             3.4   \n",
      "\n",
      "    master_metadata_track_name master_metadata_album_artist_name  \\\n",
      "0                Undo My Heart                     Karen Harding   \n",
      "1  HEART ATTACK (feat. lau.ra)                           BRONSON   \n",
      "2                      Someday                              Kygo   \n",
      "3                      Someday                              Kygo   \n",
      "4                      Only Us                              Kygo   \n",
      "\n",
      "  master_metadata_album_album_name                     spotify_track_uri  \\\n",
      "0                    Undo My Heart  spotify:track:4IKa5EKTmhKvV1wuTJf9Eq   \n",
      "1            HEART ATTACK / VAULTS  spotify:track:3xrSAFB6cXBHwLylbCP4sr   \n",
      "2                      Golden Hour  spotify:track:73h6Ma5QhBFrshEN2CTevS   \n",
      "3                      Golden Hour  spotify:track:73h6Ma5QhBFrshEN2CTevS   \n",
      "4                      Golden Hour  spotify:track:1SQbUQ8w21CxAhvkZvHN0u   \n",
      "\n",
      "  episode_name episode_show_name spotify_episode_uri  audiobook_title  \\\n",
      "0         None              None                None              NaN   \n",
      "1         None              None                None              NaN   \n",
      "2         None              None                None              NaN   \n",
      "3         None              None                None              NaN   \n",
      "4         None              None                None              NaN   \n",
      "\n",
      "   audiobook_uri  audiobook_chapter_uri  audiobook_chapter_title reason_start  \\\n",
      "0            NaN                    NaN                      NaN     CLICKROW   \n",
      "1            NaN                    NaN                      NaN    TRACKDONE   \n",
      "2            NaN                    NaN                      NaN    TRACKDONE   \n",
      "3            NaN                    NaN                      NaN      APPLOAD   \n",
      "4            NaN                    NaN                      NaN    TRACKDONE   \n",
      "\n",
      "  reason_end  shuffle  skipped  offline  \n",
      "0  TRACKDONE    False    False    False  \n",
      "1  TRACKDONE    False    False    False  \n",
      "2     LOGOUT    False    False    False  \n",
      "3  TRACKDONE    False    False    False  \n",
      "4  TRACKDONE    False    False    False  \n"
     ]
    }
   ],
   "source": [
    "Audio_Data_Frame_202_2025.rename(columns={'ts': 'utc_time_zone_ts'}, inplace=True)\n",
    "\n",
    "print(Audio_Data_Frame_202_2025.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the updated DataFrame with 'local_time_zone' next to 'utc_time_zone_ts':\n",
      "+----+---------------------+---------------------+------------+----------------+------------------+------------------------------+-------------------------------------+------------------------------------+--------------------------------------+----------------+---------------------+-----------------------+-------------------+-----------------+-------------------------+---------------------------+----------------+--------------+-----------+-----------+-----------+\n",
      "|    | utc_time_zone_ts    | local_time_zone     | platform   | conn_country   |   minutes_played | master_metadata_track_name   | master_metadata_album_artist_name   | master_metadata_album_album_name   | spotify_track_uri                    | episode_name   | episode_show_name   | spotify_episode_uri   |   audiobook_title |   audiobook_uri |   audiobook_chapter_uri |   audiobook_chapter_title | reason_start   | reason_end   | shuffle   | skipped   | offline   |\n",
      "|----+---------------------+---------------------+------------+----------------+------------------+------------------------------+-------------------------------------+------------------------------------+--------------------------------------+----------------+---------------------+-----------------------+-------------------+-----------------+-------------------------+---------------------------+----------------+--------------+-----------+-----------+-----------|\n",
      "|  0 | 2020-08-05 08:53:20 | 2020-08-05 14:23:20 | LINUX      | INDIA          |              3   | Undo My Heart                | Karen Harding                       | Undo My Heart                      | spotify:track:4IKa5EKTmhKvV1wuTJf9Eq |                |                     |                       |               nan |             nan |                     nan |                       nan | CLICKROW       | TRACKDONE    | False     | False     | False     |\n",
      "|  1 | 2020-08-05 08:56:50 | 2020-08-05 14:26:50 | LINUX      | INDIA          |              3.5 | HEART ATTACK (feat. lau.ra)  | BRONSON                             | HEART ATTACK / VAULTS              | spotify:track:3xrSAFB6cXBHwLylbCP4sr |                |                     |                       |               nan |             nan |                     nan |                       nan | TRACKDONE      | TRACKDONE    | False     | False     | False     |\n",
      "|  2 | 2020-08-12 09:06:32 | 2020-08-12 14:36:32 | LINUX      | INDIA          |              1.9 | Someday                      | Kygo                                | Golden Hour                        | spotify:track:73h6Ma5QhBFrshEN2CTevS |                |                     |                       |               nan |             nan |                     nan |                       nan | TRACKDONE      | LOGOUT       | False     | False     | False     |\n",
      "|  3 | 2020-08-12 09:08:46 | 2020-08-12 14:38:46 | LINUX      | INDIA          |              1.9 | Someday                      | Kygo                                | Golden Hour                        | spotify:track:73h6Ma5QhBFrshEN2CTevS |                |                     |                       |               nan |             nan |                     nan |                       nan | APPLOAD        | TRACKDONE    | False     | False     | False     |\n",
      "|  4 | 2020-08-12 09:18:47 | 2020-08-12 14:48:47 | LINUX      | INDIA          |              3.4 | Only Us                      | Kygo                                | Golden Hour                        | spotify:track:1SQbUQ8w21CxAhvkZvHN0u |                |                     |                       |               nan |             nan |                     nan |                       nan | TRACKDONE      | TRACKDONE    | False     | False     | False     |\n",
      "+----+---------------------+---------------------+------------+----------------+------------------+------------------------------+-------------------------------------+------------------------------------+--------------------------------------+----------------+---------------------+-----------------------+-------------------+-----------------+-------------------------+---------------------------+----------------+--------------+-----------+-----------+-----------+\n"
     ]
    }
   ],
   "source": [
    "import pytz\n",
    "from datetime import datetime\n",
    "\n",
    "timezones = {\n",
    "    'INDIA': 'Asia/Kolkata',  # India\n",
    "    'UNITED STATES': 'US/Eastern',    # United States (EST/EDT)\n",
    "    'GERMANY': 'Europe/Berlin', # Germany (CET/CEST)\n",
    "    'PUERTO RICO': 'America/Puerto_Rico', # Puerto Rico\n",
    "    'UNITED KINGDOM': 'Europe/London'  # United Kingdom (GMT/BST)\n",
    "}\n",
    "\n",
    "# Convert 'utc_time_zone_ts' to datetime\n",
    "Audio_Data_Frame_202_2025['utc_time_zone_ts'] = pd.to_datetime(Audio_Data_Frame_202_2025['utc_time_zone_ts'], utc=True)\n",
    "\n",
    "# Function to convert UTC to local time\n",
    "def convert_to_local_time(row):\n",
    "    utc_time = row['utc_time_zone_ts']\n",
    "    country = row['conn_country']\n",
    "    if country in timezones:\n",
    "        local_tz = pytz.timezone(timezones[country])\n",
    "        local_time = utc_time.astimezone(local_tz)\n",
    "        return local_time\n",
    "    else:\n",
    "        return utc_time\n",
    "\n",
    "# Apply the conversion function to create the 'local_time_zone' column\n",
    "Audio_Data_Frame_202_2025['local_time_zone'] = Audio_Data_Frame_202_2025.apply(convert_to_local_time, axis=1)\n",
    "\n",
    "# Reorder the columns to move 'local_time_zone' next to 'utc_time_zone_ts'\n",
    "cols = list(Audio_Data_Frame_202_2025.columns)\n",
    "utc_index = cols.index('utc_time_zone_ts')\n",
    "cols.insert(utc_index + 1, cols.pop(cols.index('local_time_zone')))\n",
    "Audio_Data_Frame_202_2025 = Audio_Data_Frame_202_2025[cols]\n",
    "\n",
    "Audio_Data_Frame_202_2025['utc_time_zone_ts'] = Audio_Data_Frame_202_2025['utc_time_zone_ts'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "Audio_Data_Frame_202_2025['local_time_zone'] = Audio_Data_Frame_202_2025['local_time_zone'].apply(lambda x: x.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "# Display the first few rows of the updated DataFrame in table format\n",
    "print(\"First few rows of the updated DataFrame with 'local_time_zone' next to 'utc_time_zone_ts':\")\n",
    "print(tabulate(Audio_Data_Frame_202_2025.head(), headers='keys', tablefmt='psql'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+---------------------+---------------------+---------+-----+------------------------------------+----------------+-----------------------+--------------------------------------+----------------------------------------------------------------------------------------------------+---------------------------------+----------------------------------------+-----+-----+-----+-----+-----------+-----------+-------+-------+-------+\n",
      "| 0 | GERMANY        | 2023-12-28 15:55:43 | 2023-12-28 16:55:43 | IOS     | 0.4 | Kashmeeru                          | Manan Bhardwaj | ANIMAL (TELUGU)       | spotify:track:1brtmiixpIAspQgZEQKkLH |                                                                                                    |                                 |                                        | nan | nan | nan | nan | TRACKDONE | LOGOUT    | False | False | False |\n",
      "| 1 | INDIA          | 2020-08-05 08:53:20 | 2020-08-05 14:23:20 | LINUX   | 3   | Undo My Heart                      | Karen Harding  | Undo My Heart         | spotify:track:4IKa5EKTmhKvV1wuTJf9Eq | Exercise and Alcohol                                                                               | Get Fit With Biglee             | spotify:episode:1NQibItXhXp2OqO8IUmcdZ | nan | nan | nan | nan | CLICKROW  | TRACKDONE | False | False | False |\n",
      "| 2 | PUERTO RICO    | 2024-08-29 20:51:52 | 2024-08-29 16:51:52 | ANDROID | 0.9 | Adventure of a Lifetime            | Coldplay       | A Head Full of Dreams | spotify:track:69uxyAqqPIsUyTO8txoP2M |                                                                                                    |                                 |                                        | nan | nan | nan | nan | PLAYBTN   | LOGOUT    | True  | False | False |\n",
      "| 3 | UNITED KINGDOM | 2024-01-16 08:16:50 | 2024-01-16 08:16:50 | ANDROID | 3.6 | Husn                               | Anuv Jain      | Husn                  | spotify:track:0TL0LFcwIBF5eX7arDIKxY |                                                                                                    |                                 |                                        | nan | nan | nan | nan | CLICKROW  | TRACKDONE | False | False | False |\n",
      "| 4 | UNITED STATES  | 2023-08-17 14:14:47 | 2023-08-17 10:14:47 | ANDROID | 0.2 | Sakhiyeee - From \"Thrissur Pooram\" | Haricharan     | Sakhiyeee             | spotify:track:1h9a23OsWfQbrazCujBqlc | BE RUTHLESS - The Most Powerful Motivational Speech Compilation for Success, Running & Working Out | Motivation Daily by Motiversity | spotify:episode:0bWTCe5XEbZNkKDEiVoydX | nan | nan | nan | nan | CLICKROW  | ENDPLAY   | False | True  | False |\n",
      "+---+----------------+---------------------+---------------------+---------+-----+------------------------------------+----------------+-----------------------+--------------------------------------+----------------------------------------------------------------------------------------------------+---------------------------------+----------------------------------------+-----+-----+-----+-----+-----------+-----------+-------+-------+-------+\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(Audio_Data_Frame_202_2025.groupby('conn_country').first().reset_index(),tablefmt='psql' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv_file_path = 'Audio_Data_Frame_Final_2020_2025.csv'\n",
    "#Audio_Data_Frame_202_2025.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------+---------------------+------------+----------------+------------------+------------------------------+-------------------------------------+------------------------------------+--------------------------------------+----------------+---------------------+-----------------------+-------------------+-----------------+-------------------------+---------------------------+----------------+--------------+-----------+-----------+-----------+\n",
      "|    | utc_time_zone_ts    | local_time_zone     | platform   | conn_country   |   minutes_played | master_metadata_track_name   | master_metadata_album_artist_name   | master_metadata_album_album_name   | spotify_track_uri                    | episode_name   | episode_show_name   | spotify_episode_uri   |   audiobook_title |   audiobook_uri |   audiobook_chapter_uri |   audiobook_chapter_title | reason_start   | reason_end   | shuffle   | skipped   | offline   |\n",
      "|----+---------------------+---------------------+------------+----------------+------------------+------------------------------+-------------------------------------+------------------------------------+--------------------------------------+----------------+---------------------+-----------------------+-------------------+-----------------+-------------------------+---------------------------+----------------+--------------+-----------+-----------+-----------|\n",
      "|  0 | 2020-08-05 08:53:20 | 2020-08-05 14:23:20 | LINUX      | INDIA          |              3   | Undo My Heart                | Karen Harding                       | Undo My Heart                      | spotify:track:4IKa5EKTmhKvV1wuTJf9Eq |                |                     |                       |               nan |             nan |                     nan |                       nan | CLICKROW       | TRACKDONE    | False     | False     | False     |\n",
      "|  1 | 2020-08-05 08:56:50 | 2020-08-05 14:26:50 | LINUX      | INDIA          |              3.5 | HEART ATTACK (feat. lau.ra)  | BRONSON                             | HEART ATTACK / VAULTS              | spotify:track:3xrSAFB6cXBHwLylbCP4sr |                |                     |                       |               nan |             nan |                     nan |                       nan | TRACKDONE      | TRACKDONE    | False     | False     | False     |\n",
      "|  2 | 2020-08-12 09:06:32 | 2020-08-12 14:36:32 | LINUX      | INDIA          |              1.9 | Someday                      | Kygo                                | Golden Hour                        | spotify:track:73h6Ma5QhBFrshEN2CTevS |                |                     |                       |               nan |             nan |                     nan |                       nan | TRACKDONE      | LOGOUT       | False     | False     | False     |\n",
      "|  3 | 2020-08-12 09:08:46 | 2020-08-12 14:38:46 | LINUX      | INDIA          |              1.9 | Someday                      | Kygo                                | Golden Hour                        | spotify:track:73h6Ma5QhBFrshEN2CTevS |                |                     |                       |               nan |             nan |                     nan |                       nan | APPLOAD        | TRACKDONE    | False     | False     | False     |\n",
      "|  4 | 2020-08-12 09:18:47 | 2020-08-12 14:48:47 | LINUX      | INDIA          |              3.4 | Only Us                      | Kygo                                | Golden Hour                        | spotify:track:1SQbUQ8w21CxAhvkZvHN0u |                |                     |                       |               nan |             nan |                     nan |                       nan | TRACKDONE      | TRACKDONE    | False     | False     | False     |\n",
      "+----+---------------------+---------------------+------------+----------------+------------------+------------------------------+-------------------------------------+------------------------------------+--------------------------------------+----------------+---------------------+-----------------------+-------------------+-----------------+-------------------------+---------------------------+----------------+--------------+-----------+-----------+-----------+\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(Audio_Data_Frame_202_2025.head(),headers='keys',tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      utc_time_zone_ts       start_time_utc      local_time_zone platform  \\\n",
      "0  2020-08-05 08:53:20  2020-08-05 08:50:20  2020-08-05 14:23:20    LINUX   \n",
      "1  2020-08-05 08:56:50  2020-08-05 08:53:20  2020-08-05 14:26:50    LINUX   \n",
      "2  2020-08-12 09:06:32  2020-08-12 09:04:38  2020-08-12 14:36:32    LINUX   \n",
      "3  2020-08-12 09:08:46  2020-08-12 09:06:52  2020-08-12 14:38:46    LINUX   \n",
      "4  2020-08-12 09:18:47  2020-08-12 09:15:23  2020-08-12 14:48:47    LINUX   \n",
      "\n",
      "  conn_country  minutes_played   master_metadata_track_name  \\\n",
      "0        INDIA             3.0                Undo My Heart   \n",
      "1        INDIA             3.5  HEART ATTACK (feat. lau.ra)   \n",
      "2        INDIA             1.9                      Someday   \n",
      "3        INDIA             1.9                      Someday   \n",
      "4        INDIA             3.4                      Only Us   \n",
      "\n",
      "  master_metadata_album_artist_name master_metadata_album_album_name  \\\n",
      "0                     Karen Harding                    Undo My Heart   \n",
      "1                           BRONSON            HEART ATTACK / VAULTS   \n",
      "2                              Kygo                      Golden Hour   \n",
      "3                              Kygo                      Golden Hour   \n",
      "4                              Kygo                      Golden Hour   \n",
      "\n",
      "                      spotify_track_uri  ... spotify_episode_uri  \\\n",
      "0  spotify:track:4IKa5EKTmhKvV1wuTJf9Eq  ...                None   \n",
      "1  spotify:track:3xrSAFB6cXBHwLylbCP4sr  ...                None   \n",
      "2  spotify:track:73h6Ma5QhBFrshEN2CTevS  ...                None   \n",
      "3  spotify:track:73h6Ma5QhBFrshEN2CTevS  ...                None   \n",
      "4  spotify:track:1SQbUQ8w21CxAhvkZvHN0u  ...                None   \n",
      "\n",
      "  audiobook_title audiobook_uri  audiobook_chapter_uri  \\\n",
      "0             NaN           NaN                    NaN   \n",
      "1             NaN           NaN                    NaN   \n",
      "2             NaN           NaN                    NaN   \n",
      "3             NaN           NaN                    NaN   \n",
      "4             NaN           NaN                    NaN   \n",
      "\n",
      "   audiobook_chapter_title  reason_start  reason_end shuffle skipped  offline  \n",
      "0                      NaN      CLICKROW   TRACKDONE   False   False    False  \n",
      "1                      NaN     TRACKDONE   TRACKDONE   False   False    False  \n",
      "2                      NaN     TRACKDONE      LOGOUT   False   False    False  \n",
      "3                      NaN       APPLOAD   TRACKDONE   False   False    False  \n",
      "4                      NaN     TRACKDONE   TRACKDONE   False   False    False  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "# Ensure 'utc_time_zone_ts' is in datetime format\n",
    "Audio_Data_Frame_202_2025['utc_time_zone_ts'] = pd.to_datetime(Audio_Data_Frame_202_2025['utc_time_zone_ts'], utc=True)\n",
    "\n",
    "# Calculate the start time by subtracting 'minutes_played' from 'utc_time_zone_ts'\n",
    "Audio_Data_Frame_202_2025['start_time_utc'] = Audio_Data_Frame_202_2025.apply(\n",
    "    lambda row: row['utc_time_zone_ts'] - timedelta(minutes=row['minutes_played']), axis=1)\n",
    "\n",
    "# Reorder the columns to move 'start_time_utc' next to 'utc_time_zone_ts'\n",
    "cols = list(Audio_Data_Frame_202_2025.columns)\n",
    "utc_index = cols.index('utc_time_zone_ts')\n",
    "cols.insert(utc_index + 1, cols.pop(cols.index('start_time_utc')))\n",
    "Audio_Data_Frame_202_2025 = Audio_Data_Frame_202_2025[cols]\n",
    "\n",
    "# Ensure 'utc_time_zone_ts' and 'start_time_utc' are in datetime format\n",
    "Audio_Data_Frame_202_2025['utc_time_zone_ts'] = Audio_Data_Frame_202_2025['utc_time_zone_ts'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "Audio_Data_Frame_202_2025['start_time_utc'] = Audio_Data_Frame_202_2025['start_time_utc'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(Audio_Data_Frame_202_2025.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'Audio_Data_Frame_Final_v2_2020_2025.csv'\n",
    "Audio_Data_Frame_202_2025.to_csv(csv_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-12-kernel",
   "language": "python",
   "name": "py3-12-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
